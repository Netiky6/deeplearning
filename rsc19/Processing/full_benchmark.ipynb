{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU_id = 6\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time \n",
    "\n",
    "from fastai import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.tabular import *\n",
    "from fastai.basic_data import DataBunch\n",
    "from fastai.tabular import TabularModel\n",
    "\n",
    "import cudf\n",
    "\n",
    "from preproc import *\n",
    "from batchloader import *\n",
    "from helpers import get_mean_reciprocal_rank, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this notebook we want to benchmark the processing and training time for three diffrent models: \n",
    "\n",
    "- The two first models are using our CuDF processing workflow <a href=#cudf_workflow> section I </a>:\n",
    "     1.  <a href=#first_model> Model 1 </a> : CuDF processing with CPU a copy\n",
    "     2.  <a href=#second_model> Model 2 </a> : CuDF processing in-memory without copy    \n",
    "\n",
    "           \n",
    " - <a href=#third_model> Model 3 </a> : In the second <a href=#fastai_workflow> section II </a>, we are using the Fastai processing workflow to get the scores of the best model found in the section I.  We directly process and create databunch from data_pair_all.pkl dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B** : For each model, you need to re-start the kernel to free the GPU memory and be able to run all the experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz\n",
    "# load snakeviz if you want to run profiling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> <a id=batchdatabunch>New Data Bunch </a></center> </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a custom databunch fastai that takes a TensorBatchDataLoader instead of the usual torch DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchDataBunch(DataBunch):\n",
    "    \n",
    "    @classmethod\n",
    "    def remove_tfm(cls, tfm:Callable)->None:\n",
    "        \"Remove `tfm` from `self.tfms`.\"\n",
    "        if tfm in cls.tfms: cls.tfms.remove(tfm)\n",
    "            \n",
    "    @classmethod\n",
    "    def add_tfm(cls,tfm:Callable)->None:\n",
    "        \"Add `tfm` to `self.tfms`.\"\n",
    "        cls.tfms.append(tfm)\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=64, val_bs=None, \n",
    "                      num_workers:int=defaults.cpus, device:torch.device=None,\n",
    "                      collate_fn:Callable=data_collate, tfms: List[Callable]=None, \n",
    "                       size:int=None, **kwargs)->'BatchDataBunch':\n",
    "        \n",
    "        \n",
    "        cls.tfms = listify(tfms)\n",
    "        \n",
    "        \n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        \n",
    "        datasets = [TensorBatchDataset(train_ds, batch_size=bs), \n",
    "                    TensorBatchDataset(valid_ds, batch_size=bs)]\n",
    "        \n",
    "        if valid_ds is not None:\n",
    "            cls.empty_val = False\n",
    "        else:\n",
    "            cls.empty_val = True\n",
    "            \n",
    "        if test_ds is not None:\n",
    "            datasets.append(TensorBatchDataset(test_ds, batch_size=bs))\n",
    "        else: \n",
    "            datasets.append(test_ds)\n",
    "        \n",
    "        cls.device = defaults.device if device is None else device\n",
    "        \n",
    "        dls = [BatchDataLoader(d, shuffle=s, pin_memory=False, drop_last=False, device=cls.device) for d,s in\n",
    "               zip(datasets,(True,False,False)) if d is not None]\n",
    "\n",
    "        cls.path = path \n",
    "        \n",
    "        cls.dls = dls\n",
    "    \n",
    "        \n",
    "        \n",
    "        assert not isinstance(dls[0],DeviceDataLoader)\n",
    "        \n",
    "        \n",
    "        # load batch in device \n",
    "        \n",
    "        if test_ds is not None:\n",
    "            cls.train_dl, cls.valid_dl, cls.test_dl = dls\n",
    "        else: \n",
    "            cls.train_dl, cls.valid_dl = dls\n",
    "            \n",
    "            \n",
    "        cls.path = Path(path)\n",
    "        return cls\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To use the new BatchDatabunch class, we have to build the following processed tensors ( using cudf)  : \n",
    "    - train : cat_tensor, cont_tensor, label_tensor \n",
    "    \n",
    "    - valid : cat_tensor, cont_tensor, label_tensor \n",
    "    \n",
    "    - test : cat_tensor, cont_tensor, label_tensor \n",
    "    \n",
    "- The size of vocaublary of each categorical variable need to be known "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The two first models are using our CuDF processing workflow <a href=#cudf_workflow> section II </a>:\n",
    "     1.  <a href=#first_model> Model 1 </a> : CuDF processing with CPU a copy\n",
    "     2.  <a href=#second_model> Model 2 </a> : CuDF processing in-memory without copy    \n",
    "\n",
    "           \n",
    " - The <a href=#fastai_workflow> third model </a> will use the Fastai processing workflow: Directly process and create databunch from data_pair_all.pkl dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center>  <a id=cudf_workflow> Test of Tabular Learner with CuDF workflow </a></center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B:** For this section, you need to define the new custom BatchDataBunch class, if not go back to <a href=#batchdatabunch> section 1 </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. <a id=first_model> First model: Tabular Data copied to cpu </a> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cpu = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <a id=cudf_proc> Processing: Definition of train, validation and test tensors </a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train used 6.77 seconds.\n",
      "get variables names used 0.00 seconds.\n",
      "processing train used 2.78 seconds.\n",
      "read test used 3.13 seconds.\n",
      "processing test used 5.11 seconds.\n",
      "read valid used 6.58 seconds.\n",
      "processing valid used 23.40 seconds.\n",
      "The whole processing used 39.88 seconds.\n"
     ]
    }
   ],
   "source": [
    "# %%snakeviz \n",
    "# uncomment the line above to generate the snakeviz profile of preprocessing \n",
    "\n",
    "data_path = '../cache/'\n",
    "TEST = 'test'\n",
    "VALID = 'valid'\n",
    "TRAIN = 'train'\n",
    "\n",
    "start0 = time()\n",
    "data = {}\n",
    "\n",
    "############################\n",
    "#                          #\n",
    "# Fit processing train set #\n",
    "#                          #\n",
    "############################\n",
    "start = time()\n",
    "path = os.path.join(data_path,TRAIN+'.parquet' )\n",
    "ds = cudf.read_parquet(path)\n",
    "print(f\"read {TRAIN} used {time()-start:.2f} seconds.\")\n",
    "\n",
    "# get variable names \n",
    "start = time()\n",
    "cat_names = ['user_id','item_id','platform','city','device','current_filters'] + [i for i in ds.columns if i.startswith('is_')]\n",
    "cont_names = ['price','candidate_order'] + [i for i in ds.columns if i.startswith('count') or 'rank' in i or i.startswith('delta_')]\n",
    "print(f\"get variables names used {time()-start:.2f} seconds.\")\n",
    "\n",
    "# init the processing class \n",
    "proc = PreprocessDF(cat_names=cat_names, cont_names=cont_names, label_name='target', to_cpu=to_cpu)\n",
    "\n",
    "# Fit training \n",
    "start = time()\n",
    "x, y = proc.preproc_dataframe(ds, mode=TRAIN)\n",
    "print(f\"processing {TRAIN} used {time()-start:.2f} seconds.\")\n",
    "del ds\n",
    "data[TRAIN] = (x, y)\n",
    "\n",
    "############################\n",
    "#                          #\n",
    "# Transform test and valid #\n",
    "#                          #\n",
    "############################  \n",
    "ds_name = [TEST, VALID]\n",
    "for name in ds_name:\n",
    "    path = os.path.join(data_path,name+'.parquet' )\n",
    "    ds = cudf.read_parquet(path)\n",
    "\n",
    "    print(f\"read {name} used {time()-start:.2f} seconds.\")\n",
    "    start = time()\n",
    "    x, y = proc.preproc_dataframe(ds, mode=name)\n",
    "    print(f\"processing {name} used {time()-start:.2f} seconds.\")\n",
    "    data[name] = (x, y)\n",
    "    del ds\n",
    "\n",
    "print(f\"The whole processing used {time()-start0:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Benchmark : Get the best (batch size, learning rate)</h3> \n",
    "\n",
    "- Fine tune the best couple (batch_size, lr) : The criterion used is the CrossEntropy loss function \n",
    "    - The range of batch sizes is : 4096, 8192, 20480, 40960, 81920, 204800, 409600, 819200\n",
    "    - The range of max learning rate was set w.r.t to the plot of the results of the Fastai method find_lr : [6e-2, 9e-2, 2e-1] \n",
    "    \n",
    "    \n",
    "- **N.B:** Some of the batch_sizes require more than one epoch to get the best score (numbers shown in the paper). However, to the complexity of the notebook, we'll run all the training with 1 epoch as our best model (fastest training time) converges in 1 epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [4096, 8192, 20480, 40960, 81920, 204800, 409600, 819200]\n",
    "lrs = [6e-2, 9e-2, 2e-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launch training for the couple: lr: 0.06, bs: 4096 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='2088', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for dimension 1 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-73487fe8f076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# launch training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mt_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mbenchmark_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_final\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/fastai/tabular/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_cat, x_cont)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_emb\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/site-packages/fastai/tabular/models.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_emb\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for dimension 1 with size 6"
     ]
    }
   ],
   "source": [
    "# Define batch databunch \n",
    "benchmark_results = [] \n",
    "\n",
    "for batch_size in batch_sizes: \n",
    "    train = [data['train'][0][0], data['train'][0][1], data['train'][1].long()]\n",
    "    validation = [data['valid'][0][0], data['valid'][0][1], data['valid'][1].long()]\n",
    "    test = [data['test'][0][0], data['test'][0][1], data['test'][1].long()]\n",
    "    databunch = BatchDataBunch.create(train, validation, device='cuda', bs=batch_size)   \n",
    "    \n",
    "    for learning_rate in lrs: \n",
    "        print('Launch training for the couple: lr: %s, bs: %s ' %(learning_rate, batch_size))\n",
    "        #define the model \n",
    "        emb_sz = [(938604, 16), (904722, 16), (56, 4), (32763, 8), (4, 1), (27842, 8), \n",
    "                  (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]    \n",
    "\n",
    "        model = TabularModel(emb_szs = emb_sz, n_cont=25, out_sz=2, layers=[64, 32])\n",
    "\n",
    "        learn =  Learner(databunch, model, metrics=None)\n",
    "        \n",
    "        learn.loss_func = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # launch training \n",
    "        start = time()\n",
    "        learn.fit_one_cycle(1, learning_rate)\n",
    "        t_final = time() - start \n",
    "        benchmark_results.append([batch_size, learning_rate, learn.recorder.val_losses[0], 1, t_final] ) \n",
    "        del learn \n",
    "    del databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(benchmark_results)\n",
    "results.columns = ['batch size', 'learning rate', 'validation loss', 'N epochs', 'training time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=['validation loss', 'training time'], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Conclusion** The best trade-off between training time and validation loss is reached for the couple **(204800, 0.09)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Compute average validation scores of the best model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_parquet(\"./parquet_data/data_pair_all/valid.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mean / std of scores : 5 runs \n",
    "aucs = []\n",
    "mrrs = []\n",
    "times = []\n",
    "best_bs = 204800*50\n",
    "best_lr = 9e-2\n",
    "\n",
    "emb_sz = [(938604, 16), (903867, 16), (56, 4), (32763, 8), (4, 1), (27842, 8), \n",
    "          (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]    \n",
    "\n",
    "train = [data['train'][0][0], data['train'][0][1], data['train'][1].long()]\n",
    "validation = [data['valid'][0][0], data['valid'][0][1], data['valid'][1].long()]\n",
    "test = [data['test'][0][0], data['test'][0][1], data['test'][1].long()]\n",
    "databunch = BatchDataBunch.create(train, validation, device='cuda', bs=best_bs)   \n",
    "\n",
    "for i in range(5): \n",
    "    # define the model\n",
    "    model = TabularModel(emb_szs = emb_sz, n_cont=25, out_sz=2, layers=[64, 32])\n",
    "    model = model.cuda()\n",
    "    learn =  Learner(databunch, model, metrics=None)\n",
    "    learn.loss_func = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # train the model \n",
    "    start = time()\n",
    "    learn.fit_one_cycle(1, best_lr)\n",
    "    tf = time()-start\n",
    "    \n",
    "    # get validation metrics \n",
    "    yp,y_valid = learn.get_preds(databunch)\n",
    "    cv = ds[['row_id','reference','item_id', 'target']].copy()\n",
    "    cv['prob'] = yp.numpy()[:,1]\n",
    "    cv = cv.sort_values(by=['row_id','prob'],ascending=False)\n",
    "    auc = roc_auc_score(y_valid.numpy().ravel(),yp.numpy()[:,1])\n",
    "    mean_reciprocal_rank = get_mean_reciprocal_rank(cv)\n",
    "    \n",
    "    aucs.append(auc)\n",
    "    mrrs.append(mean_reciprocal_rank)\n",
    "    times.append(tf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the mrr of the best mdodel is: %s +/- %s\" %(np.mean(mrrs), np.std(mrrs)))\n",
    "\n",
    "print(\"the auc of the best mdodel is: %s +/- %s\" %(np.mean(aucs), np.std(aucs)))\n",
    "\n",
    "print(\"the best mdodel's training time is %s +/- %s\" %(np.mean(times), np.std(times)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. <a id=second_model> Second model: Tabular Data in-memory  </a> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cpu = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Processing: Definition of train, validation and test tensors </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%snakeviz \n",
    "# uncomment the line above to generate the snakeviz profile of preprocessing \n",
    "\n",
    "data_path = './parquet_data/data_pair_all'\n",
    "TEST = 'test'\n",
    "VALID = 'valid'\n",
    "TRAIN = 'train'\n",
    "\n",
    "start0 = time()\n",
    "data = {}\n",
    "\n",
    "############################\n",
    "#                          #\n",
    "# Fit processing train set #\n",
    "#                          #\n",
    "############################\n",
    "start = time()\n",
    "path = os.path.join(data_path,TRAIN+'.parquet' )\n",
    "ds = cudf.read_parquet(path)\n",
    "print(f\"read {TRAIN} used {time()-start:.2f} seconds.\")\n",
    "\n",
    "# get variable names \n",
    "start = time()\n",
    "cat_names = ['user_id','item_id','platform','city','device','current_filters'] + [i for i in ds.columns if i.startswith('is_')]\n",
    "cont_names = ['price','candidate_order'] + [i for i in ds.columns if i.startswith('count') or 'rank' in i or i.startswith('delta_')]\n",
    "print(f\"get variables names used {time()-start:.2f} seconds.\")\n",
    "\n",
    "# init the processing class \n",
    "proc = PreprocessDF(cat_names=cat_names, cont_names=cont_names, label_name='target', to_cpu=to_cpu)\n",
    "\n",
    "# Fit training \n",
    "start = time()\n",
    "x, y = proc.preproc_dataframe(ds, mode=TRAIN)\n",
    "print(f\"processing {TRAIN} used {time()-start:.2f} seconds.\")\n",
    "del ds\n",
    "data[TRAIN] = (x, y)\n",
    "\n",
    "############################\n",
    "#                          #\n",
    "# Transform test and valid #\n",
    "#                          #\n",
    "############################  \n",
    "ds_name = [TEST, VALID]\n",
    "for name in ds_name:\n",
    "    path = os.path.join(data_path,name+'.parquet' )\n",
    "    ds = cudf.read_parquet(path)\n",
    "\n",
    "    print(f\"read {name} used {time()-start:.2f} seconds.\")\n",
    "    start = time()\n",
    "    x, y = proc.preproc_dataframe(ds, mode=name)\n",
    "    print(f\"processing {name} used {time()-start:.2f} seconds.\")\n",
    "    data[name] = (x, y)\n",
    "    del ds\n",
    "\n",
    "print(f\"The whole processing used {time()-start0:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Benchmark : Get the best (batch size, learning rate)</h3> \n",
    "\n",
    "- Fine tune the best couple (batch_size, lr) : The criterion used is the CrossEntropy loss function \n",
    "    - The range of batch sizes is : 4096, 8192, 20480, 40960, 81920, 204800, 409600, 819200\n",
    "    - The range of max learning rate was set w.r.t to the plot of the results of the Fastai method find_lr : [6e-2, 9e-2, 2e-1] \n",
    "    \n",
    "    \n",
    "- **N.B:** Some of the batch_sizes require more than one epoch to get the best score (numbers shown in the paper). However, to the complexity of the notebook, we'll run all the training with 1 epoch as our best model (fastest training time) converges in 1 epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [4096, 8192, 20480, 40960, 81920, 204800, 409600, 819200]\n",
    "lrs = [6e-2, 9e-2, 2e-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch databunch \n",
    "from fastai.tabular import TabularModel\n",
    "from time import time \n",
    "benchmark_results = [] \n",
    "\n",
    "for batch_size in batch_sizes: \n",
    "    train = [data['train'][0][0], data['train'][0][1], data['train'][1].long()]\n",
    "    validation = [data['valid'][0][0], data['valid'][0][1], data['valid'][1].long()]\n",
    "    test = [data['test'][0][0], data['test'][0][1], data['test'][1].long()]\n",
    "    databunch = BatchDataBunch.create(train, validation, device='cuda', bs=batch_size)   \n",
    "    del train \n",
    "    del validation \n",
    "    del test\n",
    "    for learning_rate in lrs: \n",
    "        #define the model \n",
    "        emb_sz = [(938604, 16), (903867, 16), (56, 4), (32763, 8), (4, 1), (27842, 8), \n",
    "                  (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]    \n",
    "\n",
    "        model = TabularModel(emb_szs = emb_sz, n_cont=25, out_sz=2, layers=[64, 32])\n",
    "\n",
    "        learn =  Learner(databunch, model, metrics=None)\n",
    "        \n",
    "        learn.loss_func = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # launch training \n",
    "        start = time()\n",
    "        learn.fit_one_cycle(1, learning_rate)\n",
    "        t_final = time() - start \n",
    "        benchmark_results.append([batch_size, learning_rate, learn.recorder.val_losses[0], 1, t_final] ) \n",
    "        print('training for the couple: lr: %s, bs: %s used %.2f' %(learning_rate, batch_size, t_final))\n",
    "\n",
    "        del learn \n",
    "        del model\n",
    "        torch.cuda.empty_cache()   \n",
    "        \n",
    "    del databunch\n",
    "    torch.cuda.empty_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(benchmark_results)\n",
    "results.columns = ['batch size', 'learning rate', 'validation loss', 'N epochs', 'training time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=['training time', 'validation loss'], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion** The best trade-off between training time and validation loss is reached for the couple **(204800, 0.09)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Compute average validation scores of the best model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_mean_reciprocal_rank, roc_auc_score\n",
    "ds = pd.read_parquet(\"./parquet_data/data_pair_all/valid.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mean / std of scores : 5 runs \n",
    "aucs = []\n",
    "mrrs = []\n",
    "times = []\n",
    "best_bs = 4096*50\n",
    "best_lr = 9e-2\n",
    "\n",
    "# create databunch \n",
    "train = [data['train'][0][0], data['train'][0][1], data['train'][1].long()]\n",
    "validation = [data['valid'][0][0], data['valid'][0][1], data['valid'][1].long()]\n",
    "test = [data['test'][0][0], data['test'][0][1], data['test'][1].long()]\n",
    "databunch = BatchDataBunch.create(train, validation, device='cuda', bs=best_bs)   \n",
    "\n",
    "del train \n",
    "del validation \n",
    "del test\n",
    "\n",
    "emb_sz = [(938604, 16), (903867, 16), (56, 4), (32763, 8), (4, 1), (27842, 8), \n",
    "          (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]  \n",
    "\n",
    "# run the model 5 times to get 5 scores \n",
    "\n",
    "for i in range(5): \n",
    "    # define the model\n",
    "    model = TabularModel(emb_szs = emb_sz, n_cont=25, out_sz=2, layers=[64, 32])\n",
    "    model = model.cuda()\n",
    "    learn =  Learner(databunch, model, metrics=None)\n",
    "    learn.loss_func = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # train the model \n",
    "    start = time()\n",
    "    learn.fit_one_cycle(1, best_lr)\n",
    "    tf = time()-start\n",
    "    \n",
    "    # get validation metrics \n",
    "    yp,y_valid = learn.get_preds(databunch)\n",
    "    cv = ds[['row_id','reference','item_id', 'target']].copy()\n",
    "    cv['prob'] = yp.numpy()[:,1]\n",
    "    cv = cv.sort_values(by=['row_id','prob'],ascending=False)\n",
    "    auc = roc_auc_score(y_valid.numpy().ravel(),yp.numpy()[:,1])\n",
    "    mean_reciprocal_rank = get_mean_reciprocal_rank(cv)\n",
    "    \n",
    "    aucs.append(auc)\n",
    "    mrrs.append(mean_reciprocal_rank)\n",
    "    times.append(tf)\n",
    "    \n",
    "    del model \n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the mrr of the best mdodel is: %s +/- %s\" %(np.mean(mrrs), np.std(mrrs)))\n",
    "\n",
    "print(\"the auc of the best mdodel is: %s +/- %s\" %(np.mean(aucs), np.std(aucs)))\n",
    "\n",
    "print(\"the best mdodel's training time is %s +/- %s\" %(np.mean(times), np.std(times)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center>  <a id=fastai_workflow> Test of Tabular Learner with Fastai workflow </a></center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As the processing time is taking more than 6minutes and our purpose is to benchmark the best model using our proposed workflow against the Fastai workflow. We'll directly compute the scores of the Tabular model with batch size of 204800 and learning rate 0.09 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <a id=third_model> Fastai model </a> </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.tabular import *\n",
    "from fastai.basic_data import DataBunch\n",
    "from batchloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "data_pair = pd.read_pickle('/rapids/notebooks/jperez/recsys/cache/data_pair_all.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create pre-processed databunch </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# split to train / test \n",
    "train = data_pair[data_pair.clickout_missing==0]\n",
    "test = data_pair[data_pair.clickout_missing>0]\n",
    "print(train.shape,test.shape)\n",
    "\n",
    "# get categorical and continious variables names \n",
    "cat_names = ['user_id','item_id','platform','city','device','current_filters'] + [i for i in train.columns if i.startswith('is_')]\n",
    "cont_names = ['price','candidate_order'] + [i for i in train.columns if i.startswith('count') or 'rank' in i or i.startswith('delta_')]\n",
    "\n",
    "# define validation rows\n",
    "train['is_va'] = train.row_id%5 == 0\n",
    "del data_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "procs = [FillMissing, Categorify, Normalize]\n",
    "\n",
    "test_list = TabularList.from_df(test, path='./', cat_names=cat_names, cont_names=cont_names)\n",
    "data = (TabularList.from_df(train, path='./', cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
    "                           .split_from_df('is_va')\n",
    "                           .label_from_df(cols='target')\n",
    "                           .add_test(test_list)\n",
    "                           .databunch(num_workers=8,bs=batch_size, device='cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Compute average validation scores of the best model  </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mean / std of scores : 5 runs \n",
    "aucs = []\n",
    "mrrs = []\n",
    "times = []\n",
    "best_bs = 4096*50\n",
    "best_lr = 9e-2\n",
    "\n",
    "emb_sz = [(938604, 16), (903867, 16), (56, 4), (32763, 8), (4, 1), (27842, 8), \n",
    "          (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
    "\n",
    "for i in range(5): \n",
    "    # define the model\n",
    "    model = TabularModel(emb_szs = emb_sz, n_cont=25, out_sz=2, layers=[64, 32])\n",
    "    model = model.cuda()\n",
    "    learn =  Learner(data, model, metrics=None)\n",
    "    learn.loss_func = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # train the model \n",
    "    start = time()\n",
    "    learn.fit_one_cycle(1, best_lr)\n",
    "    tf = time()-start\n",
    "    \n",
    "    # get validation metrics \n",
    "    yp,y_valid = learn.get_preds()\n",
    "    cv = train.loc[train['is_va']>0,['row_id','reference','item_id', 'target']].copy()\n",
    "    cv['prob'] = yp.numpy()[:,1]\n",
    "    cv = cv.sort_values(by=['row_id','prob'],ascending=False)\n",
    "    auc = roc_auc_score(y_valid.numpy().ravel(),yp.numpy()[:,1])\n",
    "    mean_reciprocal_rank = get_mean_reciprocal_rank(cv)\n",
    "    \n",
    "    aucs.append(auc)\n",
    "    mrrs.append(mean_reciprocal_rank)\n",
    "    times.append(tf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the mrr of the best mdodel is: %s +/- %s\" %(np.mean(mrrs), np.std(mrrs)))\n",
    "\n",
    "print(\"the auc of the best mdodel is: %s +/- %s\" %(np.mean(aucs), np.std(aucs)))\n",
    "\n",
    "print(\"the best mdodel's training time is %s +/- %s\" %(np.mean(times), np.std(times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
