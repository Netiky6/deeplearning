{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU_id = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time \n",
    "\n",
    "from fastai import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.tabular import *\n",
    "from fastai.basic_data import DataBunch\n",
    "from fastai.tabular import TabularModel\n",
    "\n",
    "import cudf\n",
    "\n",
    "from preproc import *\n",
    "from batchloader import *\n",
    "from helpers import get_mean_reciprocal_rank, roc_auc_score\n",
    "cudf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz\n",
    "# load snakeviz if you want to run profiling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> <a id=batchdatabunch>New Data Bunch </a></center> </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a custom databunch fastai that takes a TensorBatchDataLoader instead of the usual torch DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchDataBunch(DataBunch):\n",
    "    \n",
    "    @classmethod\n",
    "    def remove_tfm(cls, tfm:Callable)->None:\n",
    "        \"Remove `tfm` from `self.tfms`.\"\n",
    "        if tfm in cls.tfms: cls.tfms.remove(tfm)\n",
    "            \n",
    "    @classmethod\n",
    "    def add_tfm(cls,tfm:Callable)->None:\n",
    "        \"Add `tfm` to `self.tfms`.\"\n",
    "        cls.tfms.append(tfm)\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=64, val_bs=None, \n",
    "                      num_workers:int=defaults.cpus, device:torch.device=None,\n",
    "                      collate_fn:Callable=data_collate, tfms: List[Callable]=None, \n",
    "                       size:int=None, **kwargs)->'BatchDataBunch':\n",
    "        \n",
    "        \n",
    "        cls.tfms = listify(tfms)\n",
    "        \n",
    "        \n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        \n",
    "        datasets = [TensorBatchDataset(train_ds, batch_size=bs), \n",
    "                    TensorBatchDataset(valid_ds, batch_size=bs)]\n",
    "        \n",
    "        if valid_ds is not None:\n",
    "            cls.empty_val = False\n",
    "        else:\n",
    "            cls.empty_val = True\n",
    "            \n",
    "        if test_ds is not None:\n",
    "            datasets.append(TensorBatchDataset(test_ds, batch_size=bs))\n",
    "        else: \n",
    "            datasets.append(test_ds)\n",
    "        \n",
    "        cls.device = defaults.device if device is None else device\n",
    "        \n",
    "        dls = [BatchDataLoader(d, shuffle=s, pin_memory=False, drop_last=False, device=cls.device) for d,s in\n",
    "               zip(datasets,(True,False,False)) if d is not None]\n",
    "\n",
    "        cls.path = path \n",
    "        \n",
    "        cls.dls = dls\n",
    "    \n",
    "        \n",
    "        \n",
    "        assert not isinstance(dls[0],DeviceDataLoader)\n",
    "        \n",
    "        \n",
    "        # load batch in device \n",
    "        \n",
    "        if test_ds is not None:\n",
    "            cls.train_dl, cls.valid_dl, cls.test_dl = dls\n",
    "        else: \n",
    "            cls.train_dl, cls.valid_dl = dls\n",
    "            \n",
    "            \n",
    "        cls.path = Path(path)\n",
    "        return cls\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config of the fastest workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cpu = False\n",
    "batch_size = 4096*50\n",
    "lr = 0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train used 5.29 seconds.\n",
      "    row_id  candidate_order  item_id  price  row_id_count       user_id  \\\n",
      "25       1                0    55109    162            25  00RL8Z82B2Z1   \n",
      "26       1                1   129343     25            25  00RL8Z82B2Z1   \n",
      "27       1                2    54824    150            25  00RL8Z82B2Z1   \n",
      "28       1                3  2297972    143            25  00RL8Z82B2Z1   \n",
      "29       1                4   109014    101            25  00RL8Z82B2Z1   \n",
      "\n",
      "       session_id   timestamp  step    action_type  reference platform  \\\n",
      "25  aff3928535f48  1541038485    16  clickout item    1257342       AU   \n",
      "26  aff3928535f48  1541038485    16  clickout item    1257342       AU   \n",
      "27  aff3928535f48  1541038485    16  clickout item    1257342       AU   \n",
      "28  aff3928535f48  1541038485    16  clickout item    1257342       AU   \n",
      "29  aff3928535f48  1541038485    16  clickout item    1257342       AU   \n",
      "\n",
      "                 city  device current_filters  clickout_missing  target  \n",
      "25  Sydney, Australia  mobile            null                 0       0  \n",
      "26  Sydney, Australia  mobile            null                 0       0  \n",
      "27  Sydney, Australia  mobile            null                 0       0  \n",
      "28  Sydney, Australia  mobile            null                 0       0  \n",
      "29  Sydney, Australia  mobile            null                 0       0  \n",
      "get variables names used 0.00 seconds.\n",
      "processing train used 4.30 seconds.\n",
      "read test used 4.62 seconds.\n",
      "processing test used 4.40 seconds.\n",
      "read valid used 4.88 seconds.\n",
      "processing valid used 6.91 seconds.\n",
      "The whole processing used 22.32 seconds.\n"
     ]
    }
   ],
   "source": [
    "# %%snakeviz \n",
    "# uncomment the line above to generate the snakeviz profile of preprocessing \n",
    "\n",
    "data_path = '../cache/'\n",
    "TEST = 'test'\n",
    "VALID = 'valid'\n",
    "TRAIN = 'train'\n",
    "\n",
    "start0 = time()\n",
    "data = {}\n",
    "\n",
    "############################\n",
    "#                          #\n",
    "# Fit processing train set #\n",
    "#                          #\n",
    "############################\n",
    "start = time()\n",
    "path = os.path.join(data_path,TRAIN+'.parquet' )\n",
    "ds = cudf.read_parquet(path)\n",
    "print(f\"read {TRAIN} used {time()-start:.2f} seconds.\")\n",
    "\n",
    "print(ds.head())\n",
    "\n",
    "# get variable names \n",
    "start = time()\n",
    "cat_names = ['user_id','item_id','platform','city','device','current_filters'] + [i for i in ds.columns if i.startswith('is_')]\n",
    "cont_names = ['price','candidate_order'] + [i for i in ds.columns if i.startswith('count') or 'rank' in i or i.startswith('delta_')]\n",
    "print(f\"get variables names used {time()-start:.2f} seconds.\")\n",
    "\n",
    "# init the processing class \n",
    "proc = PreprocessDF(cat_names=cat_names, cont_names=cont_names, label_name='target', to_cpu=to_cpu)\n",
    "\n",
    "# Fit training \n",
    "start = time()\n",
    "x, y = proc.preproc_dataframe(ds, mode=TRAIN)\n",
    "print(f\"processing {TRAIN} used {time()-start:.2f} seconds.\")\n",
    "del ds\n",
    "data[TRAIN] = (x, y)\n",
    "\n",
    "############################\n",
    "#                          #\n",
    "# Transform test and valid #\n",
    "#                          #\n",
    "############################  \n",
    "ds_name = [TEST, VALID]\n",
    "for name in ds_name:\n",
    "    path = os.path.join(data_path,name+'.parquet' )\n",
    "    ds = cudf.read_parquet(path)\n",
    "\n",
    "    print(f\"read {name} used {time()-start:.2f} seconds.\")\n",
    "    start = time()\n",
    "    x, y = proc.preproc_dataframe(ds, mode=name)\n",
    "    print(f\"processing {name} used {time()-start:.2f} seconds.\")\n",
    "    data[name] = (x, y)\n",
    "    del ds\n",
    "\n",
    "print(f\"The whole processing used {time()-start0:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [data['train'][0][0], data['train'][0][1], data['train'][1].long()]\n",
    "validation = [data['valid'][0][0], data['valid'][0][1], data['valid'][1].long()]\n",
    "test = [data['test'][0][0], data['test'][0][1], data['test'][1].long()]\n",
    "databunch = BatchDataBunch.create(train, validation, device='cuda', bs=batch_size)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.151940</td>\n",
       "      <td>0.145247</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file '/tmp/tmpg9grtpb_'. \n",
      "Embedding SnakeViz in this document...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe id='snakeviz-eaf4891c-d690-11e9-a7cf-0242c0a87f80' frameborder=0 seamless width='100%' height='1000'></iframe>\n",
       "<script>document.getElementById(\"snakeviz-eaf4891c-d690-11e9-a7cf-0242c0a87f80\").setAttribute(\"src\", \"http://\" + document.location.hostname + \":8080/snakeviz/%2Ftmp%2Ftmpg9grtpb_\")</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%snakeviz\n",
    "emb_sz = [(938604, 16), (903867, 16), (56, 4), (32763, 8), (4, 1), (27842, 8)]  \n",
    "\n",
    "model = TabularModel(emb_szs = emb_sz, n_cont=len(cont_names), out_sz=2, layers=[64, 32]).cuda()\n",
    "\n",
    "learn =  Learner(databunch, model, metrics=None)\n",
    "\n",
    "learn.loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "start = time()\n",
    "learn.fit_one_cycle(1, lr)\n",
    "t_final = time() - start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get validation metrics \n",
    "ds = pd.read_parquet(\"./parquet_data/data_pair_all/valid.parquet\")\n",
    "yp,y_valid = learn.get_preds(databunch)\n",
    "cv = ds[['row_id','reference','item_id', 'target']].copy()\n",
    "cv['prob'] = yp.numpy()[:,1]\n",
    "cv = cv.sort_values(by=['row_id','prob'],ascending=False)\n",
    "auc = roc_auc_score(y_valid.numpy().ravel(),yp.numpy()[:,1])\n",
    "mean_reciprocal_rank = get_mean_reciprocal_rank(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mrr of the best mdodel is: 0.4684004794019787 \n",
      "the auc of the best mdodel is: 0.803668717305735 \n",
      "the best mdodel's training time is 19.02902913093567 \n"
     ]
    }
   ],
   "source": [
    "print(\"the mrr of the best mdodel is: %s \" %mean_reciprocal_rank)\n",
    "\n",
    "print(\"the auc of the best mdodel is: %s \" %auc)\n",
    "\n",
    "print(\"the best mdodel's training time is %s \" %t_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
